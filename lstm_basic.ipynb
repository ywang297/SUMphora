{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle as p\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /Applications/anaconda3\r\n",
      "insight                  /Applications/anaconda3/envs/insight\r\n",
      "intro_dl                 /Applications/anaconda3/envs/intro_dl\r\n",
      "tf                    *  /Applications/anaconda3/envs/tf\r\n",
      "tf2                      /Applications/anaconda3/envs/tf2\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info -e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = tf.add(a, b)\n",
    "d = tf.subtract(b, 1)\n",
    "e = tf.multiply(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    a_data, b_data = 3.0, 6.0\n",
    "    feed_dict = {a: a_data, b: b_data}\n",
    "    output = session.run([e], feed_dict=feed_dict)\n",
    "    print(output) # 45.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_nodes = 2\n",
    "n_output_nodes = 1\n",
    "x = tf.placeholder(tf.float32, (None, n_input_nodes))\n",
    "W = tf.Variable(tf.ones((n_input_nodes, n_output_nodes)), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros(n_output_nodes), dtype=tf.float32)\n",
    "\n",
    "'''TODO: Define the operation for z (use tf.matmul to multiply W and x).'''\n",
    "z = tf.add(tf.matmul(W,x), b)\n",
    "\n",
    "'''TODO: Define the operation for out (use tf.sigmoid).'''\n",
    "out = tf.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62245935 0.62245935]\n",
      " [0.62245935 0.62245935]]\n"
     ]
    }
   ],
   "source": [
    "test_input = [[0.5, 0.5]]\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run(session=session)\n",
    "    feed_dict = {x: test_input}\n",
    "    output = session.run([out], feed_dict=feed_dict)\n",
    "    print(output[0]) # This should output 0.73105. If not, double-check your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "tweet_size = 20\n",
    "hidden_units = 256\n",
    "vocab_size = 8000\n",
    "batch_size = 32\n",
    "\n",
    "# this just makes sure that all our following operations will be placed in the right graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create a session variable that we can run later.\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the placeholder for tweets has first dimension batch_size for each tweet in a batch,\n",
    "# second dimension tweet_size for each word in the tweet, and third dimension vocab_size\n",
    "# since each word itself is represented by a one-hot vector of size vocab_size.\n",
    "# Note that we use 'None' instead of batch_size for the first dimsension.  This allows us \n",
    "# to deal with variable batch sizes\n",
    "tweets = tf.placeholder(tf.float32, [None, tweet_size, vocab_size])\n",
    "\n",
    "'''TODO: create a placeholder for the labels (our predictions).  \n",
    "   This should be a 1D vector with size = None, \n",
    "   since we are predicting one value for each tweet in the batch,\n",
    "   but we want to be able to deal with variable batch sizes.''';\n",
    "labels = tf.placeholder(tf.float32,[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (256, ?) must have rank at least 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d599031c35f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m    \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m \u001b[0mdynamically\u001b[0m \u001b[0mconstructs\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mexecuted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m    and returns the final cell state.''';\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmulti_lstm_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 694\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 694\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \"\"\"\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (256, ?) must have rank at least 3"
     ]
    }
   ],
   "source": [
    "'''TODO: create 2 LSTM Cells using BasicLSTMCell.  Note that this creates a *layer* of LSTM\n",
    "   cells, not just a single one.''';\n",
    "lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "\n",
    "\n",
    "'''TODO: create three LSTM layers by wrapping two instances of \n",
    "   lstm_cell from above in tf.contrib.rnn_cell.MultiRNNCell. Note that\n",
    "   you can use multiple cells by doing [cell1, cell2]. Also note\n",
    "   that you should use state_is_tuple=True as an argument.  This will allow\n",
    "   us to access the part of the cell state that we need later on.''';\n",
    "multi_lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1,lstm_cell_2], state_is_tuple = True)\n",
    "\n",
    "\n",
    "'''TODO: define the operation to create the RNN graph across time.  \n",
    "   tf.nn.dynamic_rnn dynamically constructs the graph when it is executed,\n",
    "   and returns the final cell state.''';\n",
    "_, final_state = tf.nn.dynamic_rnn (multi_lstm_cells, initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define this function that creates a weight matrix + bias parameter\n",
    "## and uses them to do a matrix multiplication.\n",
    "def linear(input_, output_size, name, init_bias=0.0):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(\"weights\", [shape[-1], output_size], tf.float32, tf.random_normal_initializer(stddev=1.0 / math.sqrt(shape[-1])))\n",
    "    if init_bias is None:\n",
    "        return tf.matmul(input_, W)\n",
    "    with tf.variable_scope(name):\n",
    "        b = tf.get_variable(\"bias\", [output_size], initializer=tf.constant_initializer(init_bias))\n",
    "    return tf.matmul(input_, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO: pass the final state into this linear function to multiply it \n",
    "   by the weights and add bias to get our output.\n",
    "   \n",
    "   {Quick note that we need to feed in final_state[-1][-1] into linear since \n",
    "   final_state is actually a tuple consisting of the cell state \n",
    "   (used internally for the cell to keep track of things) \n",
    "   as well as the hidden state (the output of the cell), and one of these \n",
    "   tuples for each layer. We want the hidden state for the last layer, so we use \n",
    "   final_state[-1][-1]}''';\n",
    "\n",
    "sentiment = linear(final_state[-1][-1], )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
